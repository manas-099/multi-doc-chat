{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404b50f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] =os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea15cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Questions\n",
    "questions = [\n",
    "    \"What major trends were observed in large language model (LLM) development between 2024 and 2025?\",\n",
    "    \"What improvements were made in embedding models during this time?\",\n",
    "    \"What is meant by 'agentic AI,' and how did it evolve in 2025?\",\n",
    "    \"What challenges or cautions were associated with agentic AI adoption?\",\n",
    "    \"What practical advice does the summary offer to engineers and researchers?\"\n",
    "]\n",
    "\n",
    "# List of Answers\n",
    "answers = [\n",
    "    \"The 2024–2025 period saw major LLM releases like Meta’s Llama 4 family with multimodal and mixture-of-experts features, Google’s Gemini 2.5 and Gemma models with strong on-device capabilities, and continued updates from OpenAI, Anthropic, and others such as GPT-5, Grok 4, and Claude 4.\",\n",
    "    \"OpenAI launched the text-embedding-3 family (small and large), offering better cost-performance for RAG, while Google introduced EmbeddingGemma for efficient on-device semantic search. The ecosystem overall focused on latency, recall metrics, and quantization for production use.\",\n",
    "    \"Agentic AI refers to systems that autonomously plan and execute multi-step tasks. In 2025, it became a major industry trend, with vendors releasing SDKs, production toolkits, and enterprise frameworks like Anthropic’s 'Skills' and Salesforce’s Agentforce.\",\n",
    "    \"Analysts warned of 'agent washing'—projects branded as agentic without real value. Gartner predicted over 40% of agentic AI projects might be scrapped by 2027 due to unclear ROI and high engineering costs.\",\n",
    "    \"The document advises selecting model families by task type, benchmarking embeddings for RAG pipelines, using hybrid retrieval for cost efficiency, and defining clear KPIs when building agentic systems to avoid over-generalization and failure.\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cccc4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What major trends were observed in large language model (LLM) development between 2024 and 2025?\n",
      "A: The 2024–2025 period saw major LLM releases like Meta’s Llama 4 family with multimodal and mixture-of-experts features, Google’s Gemini 2.5 and Gemma models with strong on-device capabilities, and continued updates from OpenAI, Anthropic, and others such as GPT-5, Grok 4, and Claude 4.\n",
      "\n",
      "Q: What improvements were made in embedding models during this time?\n",
      "A: OpenAI launched the text-embedding-3 family (small and large), offering better cost-performance for RAG, while Google introduced EmbeddingGemma for efficient on-device semantic search. The ecosystem overall focused on latency, recall metrics, and quantization for production use.\n",
      "\n",
      "Q: What is meant by 'agentic AI,' and how did it evolve in 2025?\n",
      "A: Agentic AI refers to systems that autonomously plan and execute multi-step tasks. In 2025, it became a major industry trend, with vendors releasing SDKs, production toolkits, and enterprise frameworks like Anthropic’s 'Skills' and Salesforce’s Agentforce.\n",
      "\n",
      "Q: What challenges or cautions were associated with agentic AI adoption?\n",
      "A: Analysts warned of 'agent washing'—projects branded as agentic without real value. Gartner predicted over 40% of agentic AI projects might be scrapped by 2027 due to unclear ROI and high engineering costs.\n",
      "\n",
      "Q: What practical advice does the summary offer to engineers and researchers?\n",
      "A: The document advises selecting model families by task type, benchmarking embeddings for RAG pipelines, using hybrid retrieval for cost efficiency, and defining clear KPIs when building agentic systems to avoid over-generalization and failure.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: print each question with its answer\n",
    "for q, a in zip(questions, answers):\n",
    "    print(f\"Q: {q}\\nA: {a}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "789139a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QA_pairs=[{\"question\":q,\"answer\":a}for q, a in zip(questions, answers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04af3415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What major trends were observed in large language model (LLM) development between 2024 and 2025?',\n",
       "  'answer': 'The 2024–2025 period saw major LLM releases like Meta’s Llama 4 family with multimodal and mixture-of-experts features, Google’s Gemini 2.5 and Gemma models with strong on-device capabilities, and continued updates from OpenAI, Anthropic, and others such as GPT-5, Grok 4, and Claude 4.'},\n",
       " {'question': 'What improvements were made in embedding models during this time?',\n",
       "  'answer': 'OpenAI launched the text-embedding-3 family (small and large), offering better cost-performance for RAG, while Google introduced EmbeddingGemma for efficient on-device semantic search. The ecosystem overall focused on latency, recall metrics, and quantization for production use.'},\n",
       " {'question': \"What is meant by 'agentic AI,' and how did it evolve in 2025?\",\n",
       "  'answer': \"Agentic AI refers to systems that autonomously plan and execute multi-step tasks. In 2025, it became a major industry trend, with vendors releasing SDKs, production toolkits, and enterprise frameworks like Anthropic’s 'Skills' and Salesforce’s Agentforce.\"},\n",
       " {'question': 'What challenges or cautions were associated with agentic AI adoption?',\n",
       "  'answer': \"Analysts warned of 'agent washing'—projects branded as agentic without real value. Gartner predicted over 40% of agentic AI projects might be scrapped by 2027 due to unclear ROI and high engineering costs.\"},\n",
       " {'question': 'What practical advice does the summary offer to engineers and researchers?',\n",
       "  'answer': 'The document advises selecting model families by task type, benchmarking embeddings for RAG pipelines, using hybrid retrieval for cost efficiency, and defining clear KPIs when building agentic systems to avoid over-generalization and failure.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b484d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(QA_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf09db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What major trends were observed in large langu...</td>\n",
       "      <td>The 2024–2025 period saw major LLM releases li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What improvements were made in embedding model...</td>\n",
       "      <td>OpenAI launched the text-embedding-3 family (s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is meant by 'agentic AI,' and how did it ...</td>\n",
       "      <td>Agentic AI refers to systems that autonomously...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What challenges or cautions were associated wi...</td>\n",
       "      <td>Analysts warned of 'agent washing'—projects br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What practical advice does the summary offer t...</td>\n",
       "      <td>The document advises selecting model families ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What major trends were observed in large langu...   \n",
       "1  What improvements were made in embedding model...   \n",
       "2  What is meant by 'agentic AI,' and how did it ...   \n",
       "3  What challenges or cautions were associated wi...   \n",
       "4  What practical advice does the summary offer t...   \n",
       "\n",
       "                                              answer  \n",
       "0  The 2024–2025 period saw major LLM releases li...  \n",
       "1  OpenAI launched the text-embedding-3 family (s...  \n",
       "2  Agentic AI refers to systems that autonomously...  \n",
       "3  Analysts warned of 'agent washing'—projects br...  \n",
       "4  The document advises selecting model families ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2680a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\notebook\\domy.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c4c16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "client=Client()\n",
    "dataset_name=\"aidommydataset\"\n",
    "#storing the dataset in langsmit d\n",
    "dataset=client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"question and expected output of respectinve question \"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f31569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['87ef4f47-9017-487c-94b0-6c0708254b13',\n",
       "  'd5b0b18f-bb12-44a5-aabd-ba77ce2fa7bd',\n",
       "  'bb9e6614-dba3-40f0-963e-d5fa3c607e30',\n",
       "  'ff5c6d3a-d537-46c1-9e9f-7d950e9fd14d',\n",
       "  '7feddda8-87b0-4646-a106-82cc2cbc2b25'],\n",
       " 'count': 5}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in questions],\n",
    "    outputs=[{\"answer\": a} for a in answers],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66a97444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\")\n",
    "\n",
    "from pathlib import Path\n",
    "from MultiDocChat.src.document_ingetion.ingest import ChatIngestor\n",
    "from MultiDocChat.src.document_chat.retriver import ConversationalRAG\n",
    "import os\n",
    "\n",
    "# Simple file adapter for local file paths\n",
    "class LocalFileAdapter:\n",
    "    \"\"\"Adapter for local file paths to work with ChatIngestor.\"\"\"\n",
    "    def __init__(self, file_path: str):\n",
    "        self.path = Path(file_path)\n",
    "        self.name = self.path.name\n",
    "    \n",
    "    def getbuffer(self) -> bytes:\n",
    "        return self.path.read_bytes()\n",
    "def answer_ai_report_question(\n",
    "    inputs: dict,\n",
    "    data_path: str = r\"C:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\data\\rag_data.txt\",\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200,\n",
    "    k: int = 5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Answer questions about the AI Engineering Report using RAG.\n",
    "    \n",
    "    Args:\n",
    "        inputs: Dictionary containing the question, e.g., {\"question\": \"What is RAG?\"}\n",
    "        data_path: Path to the AI Engineering Report text file\n",
    "        chunk_size: Size of text chunks for splitting\n",
    "        chunk_overlap: Overlap between chunks\n",
    "        k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with the answer, e.g., {\"answer\": \"RAG stands for...\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract question from inputs\n",
    "        question = inputs.get(\"question\", \"\")\n",
    "        if not question:\n",
    "            return {\"answer\": \"No question provided\"}\n",
    "        \n",
    "        # Check if file exists\n",
    "        if not Path(data_path).exists():\n",
    "            return {\"answer\": f\"Data file not found: {data_path}\"}\n",
    "        # Create file adapter\n",
    "        file_adapter = LocalFileAdapter(data_path)\n",
    "        \n",
    "        # Build index using ChatIngestor\n",
    "        ingestor = ChatIngestor(\n",
    "            temp_base_file=\"data\",\n",
    "            faiss_base_file=\"faiss_index\",\n",
    "            use_session_dirs=True\n",
    "        )\n",
    "        \n",
    "        # Build retriever\n",
    "        ingestor.built_retriver(\n",
    "            uploaded_files=[file_adapter],\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            k=k\n",
    "        )\n",
    "        \n",
    "        # Get session ID and index path\n",
    "        session_id = ingestor.session_id\n",
    "        index_path = f\"faiss_index/{session_id}\"\n",
    "        \n",
    "        # Create RAG instance and load retriever\n",
    "        rag = ConversationalRAG(session_id=session_id)\n",
    "        rag.load_retriever_from_faiss(\n",
    "            index_path=index_path,\n",
    "            k=k,\n",
    "            index_name=os.getenv(\"FAISS_INDEX_NAME\", \"index\")\n",
    "        )\n",
    "        \n",
    "        # Get answer\n",
    "        answer = rag.invoke(question, chat_history=[])\n",
    "        \n",
    "        return {\"answer\": answer}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"Error: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af0c076b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-12T09:29:19.692740Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:29:19.694741Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:29:19.695737Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:29:19.699281Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_145919_d7bfaae8\", \"temp_dir\": \"data\\\\session_20251112_145919_d7bfaae8\", \"faiss_dir\": \"faiss_index\\\\session_20251112_145919_d7bfaae8\", \"sessionized\": true, \"timestamp\": \"2025-11-12T09:29:19.702285Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_145919_d7bfaae8\\\\9163ee0d.txt\", \"timestamp\": \"2025-11-12T09:29:19.704752Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T09:29:19.710351Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T09:29:19.712360Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:29:19.713359Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_145919_d7bfaae8\", \"timestamp\": \"2025-11-12T09:29:21.763278Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T09:29:21.764277Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T09:29:21.767277Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:29:21.768284Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:29:21.769279Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:29:21.771392Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T09:29:21.773393Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_145919_d7bfaae8\", \"timestamp\": \"2025-11-12T09:29:21.779393Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_145919_d7bfaae8\", \"timestamp\": \"2025-11-12T09:29:21.779900Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T09:29:21.782909Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:29:21.784913Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:29:21.785907Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:29:21.787911Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:29:21.790431Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_145919_d7bfaae8\", \"timestamp\": \"2025-11-12T09:29:21.855441Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_145919_d7bfaae8\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_145919_d7bfaae8\", \"timestamp\": \"2025-11-12T09:29:21.856893Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_145919_d7bfaae8\", \"user_input\": \"Which companies integrated agentic AI capabilities into their enterprise products in 2025?\", \"answer_preview\": \"In 2025, companies such as Dalet, Salesforce, IBM, and Oracle integrated agentic AI capabilities into their enterprise products, offering guides and p\", \"timestamp\": \"2025-11-12T09:29:26.628463Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which companies integrated agentic AI capabilities into their enterprise products in 2025?\n",
      "\n",
      "Answer: In 2025, companies such as Dalet, Salesforce, IBM, and Oracle integrated agentic AI capabilities into their enterprise products, offering guides and product offerings for specific workflows. Additionally, vendors like Anthropic rolled out 'Skills' and OpenAI announced 'AgentKit' as part of their efforts in enterprise agents and toolkits.\n"
     ]
    }
   ],
   "source": [
    "test_input = {\"question\":  \"Which companies integrated agentic AI capabilities into their enterprise products in 2025?\"}\n",
    "result = answer_ai_report_question(test_input)\n",
    "print(\"Question:\", test_input[\"question\"])\n",
    "print(\"\\nAnswer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed4fa4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-12T09:32:18.040068Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:18.041069Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:18.042068Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:18.047535Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_150218_d5e8873e\", \"temp_dir\": \"data\\\\session_20251112_150218_d5e8873e\", \"faiss_dir\": \"faiss_index\\\\session_20251112_150218_d5e8873e\", \"sessionized\": true, \"timestamp\": \"2025-11-12T09:32:18.054537Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_150218_d5e8873e\\\\c4bcd527.txt\", \"timestamp\": \"2025-11-12T09:32:18.058535Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T09:32:18.062534Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T09:32:18.065538Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:18.068549Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing all questions from the dataset:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_150218_d5e8873e\", \"timestamp\": \"2025-11-12T09:32:20.028853Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T09:32:20.029862Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:20.033878Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:20.034962Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:20.036859Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:20.039863Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T09:32:20.041874Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_150218_d5e8873e\", \"timestamp\": \"2025-11-12T09:32:20.045861Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150218_d5e8873e\", \"timestamp\": \"2025-11-12T09:32:20.047861Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:20.050868Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:20.052860Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:20.053861Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:20.056862Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:20.057860Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_150218_d5e8873e\", \"timestamp\": \"2025-11-12T09:32:20.102285Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_150218_d5e8873e\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_150218_d5e8873e\", \"timestamp\": \"2025-11-12T09:32:20.105301Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150218_d5e8873e\", \"user_input\": \"What major trends were observed in large language model (LLM) development between 2024 and 2025?\", \"answer_preview\": \"Between 2024 and 2025, major trends in LLM development included the expansion of multimodal capabilities, such as image and video understanding, seen \", \"timestamp\": \"2025-11-12T09:32:24.760968Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:24.766933Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:24.768000Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:24.768910Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:24.771046Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_150224_c4d33f10\", \"temp_dir\": \"data\\\\session_20251112_150224_c4d33f10\", \"faiss_dir\": \"faiss_index\\\\session_20251112_150224_c4d33f10\", \"sessionized\": true, \"timestamp\": \"2025-11-12T09:32:24.773902Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_150224_c4d33f10\\\\bd8a852c.txt\", \"timestamp\": \"2025-11-12T09:32:24.775912Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T09:32:24.779900Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T09:32:24.781920Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:24.784896Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: What major trends were observed in large language model (LLM) development between 2024 and 2025?\n",
      "A1: Between 2024 and 2025, major trends in LLM development included the expansion of multimodal capabilities, such as image and video understanding, seen in Meta's Llama 4 family and Google's Gemini models. There was also an increased adoption of mixture-of-experts architectures to enhance efficiency. Additionally, companies like OpenAI, Alibaba, Anthropic, Mistral, and Falcon continued to release iterative models, expanding available choices with varied licensing and sizes.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_150224_c4d33f10\", \"timestamp\": \"2025-11-12T09:32:26.664666Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T09:32:26.666676Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:26.669764Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:26.671674Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:26.672769Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:26.675763Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T09:32:26.675763Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_150224_c4d33f10\", \"timestamp\": \"2025-11-12T09:32:26.679676Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150224_c4d33f10\", \"timestamp\": \"2025-11-12T09:32:26.680676Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:26.684677Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:26.686687Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:26.687676Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:26.691759Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:26.693677Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_150224_c4d33f10\", \"timestamp\": \"2025-11-12T09:32:26.726817Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_150224_c4d33f10\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_150224_c4d33f10\", \"timestamp\": \"2025-11-12T09:32:26.728805Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150224_c4d33f10\", \"user_input\": \"What improvements were made in embedding models during this time?\", \"answer_preview\": \"During 2024-2025, embedding models saw improvements including OpenAI's text-embedding-3 family, which aimed for lower cost and better performance for \", \"timestamp\": \"2025-11-12T09:32:34.193543Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:34.196961Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:34.197973Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:34.200977Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:34.203978Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_150234_b7012e05\", \"temp_dir\": \"data\\\\session_20251112_150234_b7012e05\", \"faiss_dir\": \"faiss_index\\\\session_20251112_150234_b7012e05\", \"sessionized\": true, \"timestamp\": \"2025-11-12T09:32:34.205972Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_150234_b7012e05\\\\5366af99.txt\", \"timestamp\": \"2025-11-12T09:32:34.208972Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T09:32:34.212678Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T09:32:34.213693Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:34.215685Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: What improvements were made in embedding models during this time?\n",
      "A2: During 2024-2025, embedding models saw improvements including OpenAI's text-embedding-3 family, which aimed for lower cost and better performance for retrieval/RAG. Specialized and on-device embeddings, like Google's EmbeddingGemma, were released for small-footprint, multilingual applications. The ecosystem also matured, with a focus on benchmarks like Recall@k, p95 latency, and optimization for production.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_150234_b7012e05\", \"timestamp\": \"2025-11-12T09:32:35.684029Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T09:32:35.685021Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:35.688022Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:35.689024Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:35.690022Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:35.693072Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T09:32:35.694089Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_150234_b7012e05\", \"timestamp\": \"2025-11-12T09:32:35.699022Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150234_b7012e05\", \"timestamp\": \"2025-11-12T09:32:35.701021Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:35.705023Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:35.706026Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:35.707021Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:35.710023Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:35.712023Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_150234_b7012e05\", \"timestamp\": \"2025-11-12T09:32:35.748029Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_150234_b7012e05\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_150234_b7012e05\", \"timestamp\": \"2025-11-12T09:32:35.752050Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150234_b7012e05\", \"user_input\": \"What is meant by 'agentic AI,' and how did it evolve in 2025?\", \"answer_preview\": \"Agentic AI refers to systems that autonomously plan and execute multi-step tasks. In 2025, it emerged as a prominent strategic trend, with vendors rol\", \"timestamp\": \"2025-11-12T09:32:40.509254Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:40.512264Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:40.514544Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:40.515546Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:40.519540Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_150240_8932a980\", \"temp_dir\": \"data\\\\session_20251112_150240_8932a980\", \"faiss_dir\": \"faiss_index\\\\session_20251112_150240_8932a980\", \"sessionized\": true, \"timestamp\": \"2025-11-12T09:32:40.521540Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_150240_8932a980\\\\8a8a3dce.txt\", \"timestamp\": \"2025-11-12T09:32:40.524542Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T09:32:40.528569Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T09:32:40.529890Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:40.531904Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: What is meant by 'agentic AI,' and how did it evolve in 2025?\n",
      "A3: Agentic AI refers to systems that autonomously plan and execute multi-step tasks. In 2025, it emerged as a prominent strategic trend, with vendors rolling out SDKs, production-focused toolkits, and enterprise agents like Anthropic 'Skills' and OpenAI AgentKit. Additionally, major companies such as Dalet, Salesforce, IBM, and Oracle published guides and product offerings to integrate agentic capabilities into specific enterprise workflows.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_150240_8932a980\", \"timestamp\": \"2025-11-12T09:32:42.387292Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T09:32:42.389403Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:42.392401Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:42.393406Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:42.394402Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:42.397413Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T09:32:42.399418Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_150240_8932a980\", \"timestamp\": \"2025-11-12T09:32:42.402400Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150240_8932a980\", \"timestamp\": \"2025-11-12T09:32:42.404399Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:42.407401Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:42.408401Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:42.409401Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:42.412401Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:42.413402Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_150240_8932a980\", \"timestamp\": \"2025-11-12T09:32:42.458507Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_150240_8932a980\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_150240_8932a980\", \"timestamp\": \"2025-11-12T09:32:42.459507Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150240_8932a980\", \"user_input\": \"What challenges or cautions were associated with agentic AI adoption?\", \"answer_preview\": \"Industry analysts warned of \\\"agent washing\\\" and predicted many agentic projects would fail to deliver ROI without clear business value and engineering\", \"timestamp\": \"2025-11-12T09:32:47.037170Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:47.042475Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:47.044482Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:47.046473Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:47.053689Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_150247_4a4d060f\", \"temp_dir\": \"data\\\\session_20251112_150247_4a4d060f\", \"faiss_dir\": \"faiss_index\\\\session_20251112_150247_4a4d060f\", \"sessionized\": true, \"timestamp\": \"2025-11-12T09:32:47.058677Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_150247_4a4d060f\\\\4037f551.txt\", \"timestamp\": \"2025-11-12T09:32:47.064721Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T09:32:47.068850Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T09:32:47.070846Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:47.073100Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4: What challenges or cautions were associated with agentic AI adoption?\n",
      "A4: Industry analysts warned of \"agent washing\" and predicted many agentic projects would fail to deliver ROI without clear business value and engineering investment. Gartner estimated that over 40% of agentic AI projects might be scrapped by the end of 2027 due to high costs and unclear value. Additionally, building agentic systems requires heavy engineering and maintenance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_150247_4a4d060f\", \"timestamp\": \"2025-11-12T09:32:48.966948Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T09:32:48.970953Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:48.977013Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:48.978948Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:48.981950Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:48.988950Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T09:32:48.990948Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_150247_4a4d060f\", \"timestamp\": \"2025-11-12T09:32:48.998383Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150247_4a4d060f\", \"timestamp\": \"2025-11-12T09:32:49.001877Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:49.007881Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:49.009880Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T09:32:49.010881Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T09:32:49.017382Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T09:32:49.018490Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_150247_4a4d060f\", \"timestamp\": \"2025-11-12T09:32:49.119305Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_150247_4a4d060f\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_150247_4a4d060f\", \"timestamp\": \"2025-11-12T09:32:49.121304Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_150247_4a4d060f\", \"user_input\": \"What practical advice does the summary offer to engineers and researchers?\", \"answer_preview\": \"For engineers and researchers, the summary advises choosing the right model family for the task, with top-tier closed models favored for reasoning/mat\", \"timestamp\": \"2025-11-12T09:33:04.600217Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5: What practical advice does the summary offer to engineers and researchers?\n",
      "A5: For engineers and researchers, the summary advises choosing the right model family for the task, with top-tier closed models favored for reasoning/math/coding and open models for customization. For retrieval and RAG, it recommends benchmarking embeddings on specific data, considering hybrid pipelines, and optimizing for cost and latency. When building agentic systems, it's crucial to start with clear KPIs, limit scope, invest in orchestration and tool safety, and avoid premature generalization claims.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing all questions from the dataset:\\n\")\n",
    "for i, q in enumerate(questions, 1):\n",
    "    test_input = {\"question\": q}\n",
    "    result = answer_ai_report_question(test_input)\n",
    "    print(f\"Q{i}: {q}\")\n",
    "    print(f\"A{i}: {result['answer']}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f766caa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.evaluation'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangsmith\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate,LangChainStringEvaluator\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#evaluator\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m qa_evaluator=[\u001b[43mLangChainStringEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcot_qa\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[32m      4\u001b[39m dataset_name=\u001b[33m\"\u001b[39m\u001b[33maidommydataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m experiment_results=evaluate(\n\u001b[32m      6\u001b[39m     answer_ai_report_question,\n\u001b[32m      7\u001b[39m     data=dataset_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\integrations\\_langchain.py:162\u001b[39m, in \u001b[36mLangChainStringEvaluator.__init__\u001b[39m\u001b[34m(self, evaluator, config, prepare_data)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    148\u001b[39m     evaluator: Union[StringEvaluator, \u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m     ] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    154\u001b[39m ):\n\u001b[32m    155\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize a LangChainStringEvaluator.\u001b[39;00m\n\u001b[32m    156\u001b[39m \n\u001b[32m    157\u001b[39m \u001b[33;03m    See: https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.StringEvaluator.html#langchain-evaluation-schema-stringevaluator\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    160\u001b[39m \u001b[33;03m        evaluator (StringEvaluator): The underlying StringEvaluator.\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringEvaluator  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator, StringEvaluator):\n\u001b[32m    165\u001b[39m         \u001b[38;5;28mself\u001b[39m.evaluator = evaluator\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.evaluation'"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate,LangChainStringEvaluator\n",
    "#evaluator\n",
    "qa_evaluator=[LangChainStringEvaluator(\"cot_qa\")]\n",
    "dataset_name=\"aidommydataset\"\n",
    "experiment_results=evaluate(\n",
    "    answer_ai_report_question,\n",
    "    data=dataset_name,\n",
    "    evaluators=qa_evaluator,\n",
    "    experiment_prefix=\"test airag\",\n",
    "    # Experiment metadata\n",
    "    metadata={\n",
    "        \"variant\": \"RAG with FAISS and AI Engineering Report\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec16c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'test_airag-e5c5410a' at:\n",
      "https://smith.langchain.com/o/e92dd95e-0a41-4dd5-a85e-23f891be8c42/datasets/4133aa80-e314-4124-bfb0-d989d1a551fe/compare?selectedSessions=a9a9dd29-1c40-4d18-b3cf-9b4e632a6e2b\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'correctness' is not a callable object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m dataset_name = \u001b[33m\"\u001b[39m\u001b[33maidommydataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m experiment_results = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_ai_report_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ✅ the callable function\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcorrectness\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ✅ built-in LangSmith evaluator\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest_airag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvariant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRAG with FAISS and AI Engineering Report\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchunk_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchunk_overlap\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mk\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(experiment_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:423\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:1094\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling)\u001b[39m\n\u001b[32m   1089\u001b[39m     manager = manager.with_predictions(\n\u001b[32m   1090\u001b[39m         cast(TARGET_T, target), max_concurrency=max_concurrency\n\u001b[32m   1091\u001b[39m     )\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m evaluators:\n\u001b[32m   1093\u001b[39m     \u001b[38;5;66;03m# Apply evaluators to the predictions.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     manager = \u001b[43mmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_evaluators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m summary_evaluators:\n\u001b[32m   1098\u001b[39m     \u001b[38;5;66;03m# Apply the experiment-level summary evaluators.\u001b[39;00m\n\u001b[32m   1099\u001b[39m     manager = manager.with_summary_evaluators(summary_evaluators)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:1491\u001b[39m, in \u001b[36m_ExperimentManager.with_evaluators\u001b[39m\u001b[34m(self, evaluators, max_concurrency)\u001b[39m\n\u001b[32m   1479\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_evaluators\u001b[39m(\n\u001b[32m   1480\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1481\u001b[39m     evaluators: Sequence[\n\u001b[32m   (...)\u001b[39m\u001b[32m   1488\u001b[39m     max_concurrency: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1489\u001b[39m ) -> _ExperimentManager:\n\u001b[32m   1490\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Lazily apply the provided evaluators to the experiment.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m     evaluators = \u001b[43m_resolve_evaluators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m     context = copy_context()\n\u001b[32m   1493\u001b[39m     experiment_results = context.run(\n\u001b[32m   1494\u001b[39m         \u001b[38;5;28mself\u001b[39m._score, evaluators, max_concurrency=max_concurrency\n\u001b[32m   1495\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:1847\u001b[39m, in \u001b[36m_resolve_evaluators\u001b[39m\u001b[34m(evaluators)\u001b[39m\n\u001b[32m   1845\u001b[39m         results.append(evaluator.as_run_evaluator())\n\u001b[32m   1846\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m         results.append(\u001b[43mrun_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py:422\u001b[39m, in \u001b[36mrun_evaluator\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m    413\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_evaluator\u001b[39m(\n\u001b[32m    414\u001b[39m     func: Callable[\n\u001b[32m    415\u001b[39m         [Run, Optional[Example]], Union[_RUNNABLE_OUTPUT, Awaitable[_RUNNABLE_OUTPUT]]\n\u001b[32m    416\u001b[39m     ],\n\u001b[32m    417\u001b[39m ):\n\u001b[32m    418\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a run evaluator from a function.\u001b[39;00m\n\u001b[32m    419\u001b[39m \n\u001b[32m    420\u001b[39m \u001b[33;03m    Decorator that transforms a function into a `RunEvaluator`.\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDynamicRunEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py:212\u001b[39m, in \u001b[36mDynamicRunEvaluator.__init__\u001b[39m\u001b[34m(self, func, afunc)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    193\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    194\u001b[39m     func: Callable[\n\u001b[32m   (...)\u001b[39m\u001b[32m    204\u001b[39m     ] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    205\u001b[39m ):\n\u001b[32m    206\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize the DynamicRunEvaluator with a given function.\u001b[39;00m\n\u001b[32m    207\u001b[39m \n\u001b[32m    208\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[33;03m        func (Callable): A function that takes a `Run` and an optional `Example` as\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[33;03m        arguments, and returns a dict or `ComparisonEvaluationResult`.\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     (func, prepare_inputs) = \u001b[43m_normalize_evaluator_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m afunc:\n\u001b[32m    214\u001b[39m         (afunc, prepare_inputs) = _normalize_evaluator_func(afunc)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\manas\\OneDrive\\Desktop\\multi-doc-chat\\.venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py:666\u001b[39m, in \u001b[36m_normalize_evaluator_func\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_normalize_evaluator_func\u001b[39m(\n\u001b[32m    650\u001b[39m     func: Callable,\n\u001b[32m    651\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\n\u001b[32m   (...)\u001b[39m\u001b[32m    656\u001b[39m     Optional[Callable[..., \u001b[38;5;28mdict\u001b[39m]],\n\u001b[32m    657\u001b[39m ]:\n\u001b[32m    658\u001b[39m     supported_args = (\n\u001b[32m    659\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrun\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    660\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mexample\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    664\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mattachments\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    665\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     sig = \u001b[43minspect\u001b[49m\u001b[43m.\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    667\u001b[39m     all_args = [pname \u001b[38;5;28;01mfor\u001b[39;00m pname, p \u001b[38;5;129;01min\u001b[39;00m sig.parameters.items() \u001b[38;5;28;01mif\u001b[39;00m p.kind != p.VAR_KEYWORD]\n\u001b[32m    668\u001b[39m     args_with_defaults = [\n\u001b[32m    669\u001b[39m         pname\n\u001b[32m    670\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m pname, p \u001b[38;5;129;01min\u001b[39;00m sig.parameters.items()\n\u001b[32m    671\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m p.default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect.Parameter.empty\n\u001b[32m    672\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\inspect.py:3341\u001b[39m, in \u001b[36msignature\u001b[39m\u001b[34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[39m\n\u001b[32m   3339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msignature\u001b[39m(obj, *, follow_wrapped=\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, eval_str=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   3340\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3342\u001b[39m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\inspect.py:3081\u001b[39m, in \u001b[36mSignature.from_callable\u001b[39m\u001b[34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[39m\n\u001b[32m   3077\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   3078\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, *,\n\u001b[32m   3079\u001b[39m                   follow_wrapped=\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, eval_str=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   3080\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3081\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\inspect.py:2518\u001b[39m, in \u001b[36m_signature_from_callable\u001b[39m\u001b[34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[39m\n\u001b[32m   2509\u001b[39m _get_signature_of = functools.partial(_signature_from_callable,\n\u001b[32m   2510\u001b[39m                             follow_wrapper_chains=follow_wrapper_chains,\n\u001b[32m   2511\u001b[39m                             skip_bound_arg=skip_bound_arg,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2514\u001b[39m                             sigcls=sigcls,\n\u001b[32m   2515\u001b[39m                             eval_str=eval_str)\n\u001b[32m   2517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(obj):\n\u001b[32m-> \u001b[39m\u001b[32m2518\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m is not a callable object\u001b[39m\u001b[33m'\u001b[39m.format(obj))\n\u001b[32m   2520\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types.MethodType):\n\u001b[32m   2521\u001b[39m     \u001b[38;5;66;03m# In this case we skip the first parameter of the underlying\u001b[39;00m\n\u001b[32m   2522\u001b[39m     \u001b[38;5;66;03m# function (usually `self` or `cls`).\u001b[39;00m\n\u001b[32m   2523\u001b[39m     sig = _get_signature_of(obj.\u001b[34m__func__\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'correctness' is not a callable object"
     ]
    }
   ],
   "source": [
    "from langsmith import evaluate, Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Wrapper to adapt your RAG function to LangSmith's expected signature\n",
    "def run_ai_report_eval(example: dict):\n",
    "    \"\"\"\n",
    "    LangSmith expects a function that takes a dataset row (example)\n",
    "    and returns a string or dict answer.\n",
    "    \"\"\"\n",
    "    question = example.get(\"input\") or example.get(\"question\")\n",
    "    result = answer_ai_report_question({\"question\": question})\n",
    "    # Return only the answer string (LangSmith prefers plain text output)\n",
    "    return result[\"answer\"]\n",
    "\n",
    "# Dataset in your LangSmith workspace\n",
    "dataset_name = \"aidommydataset\"\n",
    "\n",
    "# Run evaluation\n",
    "experiment_results = evaluate(\n",
    "    run_ai_report_eval,  # ✅ the callable function\n",
    "    data=dataset_name,\n",
    "    evaluators=[\"correctness\"],  # ✅ built-in LangSmith evaluator\n",
    "    experiment_prefix=\"test_airag\",\n",
    "    metadata={\n",
    "        \"variant\": \"RAG with FAISS and AI Engineering Report\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(experiment_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e5e2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom\n",
    "from langsmith.schemas import Run, Example\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def correctness_evaluator(run: Run, example: Example) -> dict:\n",
    "    \"\"\"\n",
    "    Custom LLM-as-a-Judge evaluator for correctness.\n",
    "    \n",
    "    Correctness means how well the actual model output matches the reference output \n",
    "    in terms of factual accuracy, coverage, and meaning.\n",
    "    \n",
    "    Args:\n",
    "        run: The Run object containing the actual outputs\n",
    "        example: The Example object containing the expected outputs\n",
    "    \n",
    "    Returns:\n",
    "        dict with 'score' (1 for correct, 0 for incorrect) and 'reasoning'\n",
    "    \"\"\"\n",
    "    # Extract actual and expected outputs\n",
    "    actual_output = run.outputs.get(\"answer\", \"\")\n",
    "    expected_output = example.outputs.get(\"answer\", \"\")\n",
    "    input_question = example.inputs.get(\"question\", \"\")\n",
    "    \n",
    "    # Define the evaluation prompt\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an evaluator whose job is to judge correctness.\n",
    "\n",
    "Correctness means how well the actual model output matches the reference output in terms of factual accuracy, coverage, and meaning.\n",
    "\n",
    "- If the actual output matches the reference output semantically (even if wording differs), it should be marked correct.\n",
    "- If the output misses key facts, introduces contradictions, or is factually incorrect, it should be marked incorrect.\n",
    "\n",
    "Do not penalize for stylistic or formatting differences unless they change meaning.\"\"\"),\n",
    "        (\"human\", \"\"\"<example>\n",
    "<input>\n",
    "{input}\n",
    "</input>\n",
    "\n",
    "<output>\n",
    "Expected Output: {expected_output}\n",
    "\n",
    "Actual Output: {actual_output}\n",
    "</output>\n",
    "</example>\n",
    "\n",
    "Please grade the following agent run given the input, expected output, and actual output.\n",
    "Focus only on correctness (semantic and factual alignment).\n",
    "\n",
    "Respond with:\n",
    "1. A brief reasoning (1-2 sentences)\n",
    "2. A final verdict: either \"CORRECT\" or \"INCORRECT\"\n",
    "\n",
    "Format your response as:\n",
    "Reasoning: [your reasoning]\n",
    "Verdict: [CORRECT or INCORRECT]\"\"\")\n",
    "    ])\n",
    "    \n",
    "    # Initialize LLM (using Gemini as shown in your config)\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-pro\",\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Create chain and invoke\n",
    "    chain = eval_prompt | llm\n",
    "    \n",
    "    try:\n",
    "        response = chain.invoke({\n",
    "            \"input\": input_question,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"actual_output\": actual_output\n",
    "        })\n",
    "        \n",
    "        response_text = response.content\n",
    "        \n",
    "        # Parse the response\n",
    "        reasoning = \"\"\n",
    "        verdict = \"\"\n",
    "        \n",
    "        for line in response_text.split('\\n'):\n",
    "            if line.startswith(\"Reasoning:\"):\n",
    "                reasoning = line.replace(\"Reasoning:\", \"\").strip()\n",
    "            elif line.startswith(\"Verdict:\"):\n",
    "                verdict = line.replace(\"Verdict:\", \"\").strip()\n",
    "        \n",
    "        # Convert verdict to score (1 for correct, 0 for incorrect)\n",
    "        score = 1 if \"CORRECT\" in verdict.upper() else 0\n",
    "        \n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": score,\n",
    "            \"reasoning\": reasoning,\n",
    "            \"comment\": f\"Verdict: {verdict}\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": 0,\n",
    "            \"reasoning\": f\"Error during evaluation: {str(e)}\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c29cb69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"timestamp\": \"2025-11-12T10:02:38.024547Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:02:38.033908Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:02:38.036913Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:02:38.055270Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_153238_5f071eec\", \"temp_dir\": \"data\\\\session_20251112_153238_5f071eec\", \"faiss_dir\": \"faiss_index\\\\session_20251112_153238_5f071eec\", \"sessionized\": true, \"timestamp\": \"2025-11-12T10:02:38.060933Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_153238_5f071eec\\\\9bbb066c.txt\", \"timestamp\": \"2025-11-12T10:02:38.068270Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T10:02:38.088444Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T10:02:38.094442Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:02:38.097800Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'ai_rag-cf0f6eb4' at:\n",
      "https://smith.langchain.com/o/e92dd95e-0a41-4dd5-a85e-23f891be8c42/datasets/4133aa80-e314-4124-bfb0-d989d1a551fe/compare?selectedSessions=f615b6b1-a343-46ab-9899-7b76be138e98\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_153238_5f071eec\", \"timestamp\": \"2025-11-12T10:02:40.879510Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T10:02:40.882519Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T10:02:40.890165Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:02:40.891169Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:02:40.892166Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:02:40.896674Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T10:02:40.898693Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_153238_5f071eec\", \"timestamp\": \"2025-11-12T10:02:40.911157Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153238_5f071eec\", \"timestamp\": \"2025-11-12T10:02:40.913159Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T10:02:40.916161Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:02:40.918170Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:02:40.920181Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:02:40.924181Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:02:40.927180Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_153238_5f071eec\", \"timestamp\": \"2025-11-12T10:02:41.004696Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_153238_5f071eec\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_153238_5f071eec\", \"timestamp\": \"2025-11-12T10:02:41.005694Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153238_5f071eec\", \"user_input\": \"What major trends were observed in large language model (LLM) development between 2024 and 2025?\", \"answer_preview\": \"Between 2024 and 2025, major trends in LLM development included the expansion of multimodal capabilities, such as image and video understanding, seen \", \"timestamp\": \"2025-11-12T10:02:46.362861Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-12T10:03:13.141243Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:03:13.143255Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:03:13.144309Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:03:13.152247Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_153313_e2b7d15d\", \"temp_dir\": \"data\\\\session_20251112_153313_e2b7d15d\", \"faiss_dir\": \"faiss_index\\\\session_20251112_153313_e2b7d15d\", \"sessionized\": true, \"timestamp\": \"2025-11-12T10:03:13.156244Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_153313_e2b7d15d\\\\26f8472f.txt\", \"timestamp\": \"2025-11-12T10:03:13.160242Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T10:03:13.166579Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T10:03:13.168702Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:03:13.170702Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_153313_e2b7d15d\", \"timestamp\": \"2025-11-12T10:03:14.797332Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T10:03:14.800415Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T10:03:14.803802Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:03:14.804800Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:03:14.806089Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:03:14.809404Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T10:03:14.810504Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_153313_e2b7d15d\", \"timestamp\": \"2025-11-12T10:03:14.816487Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153313_e2b7d15d\", \"timestamp\": \"2025-11-12T10:03:14.817753Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T10:03:14.821493Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:03:14.823424Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:03:14.824254Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:03:14.827478Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:03:14.828756Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_153313_e2b7d15d\", \"timestamp\": \"2025-11-12T10:03:14.866136Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_153313_e2b7d15d\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_153313_e2b7d15d\", \"timestamp\": \"2025-11-12T10:03:14.867230Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153313_e2b7d15d\", \"user_input\": \"What improvements were made in embedding models during this time?\", \"answer_preview\": \"During 2024-2025, embedding models saw improvements aimed at lower cost and better performance, particularly for retrieval and RAG use cases. OpenAI i\", \"timestamp\": \"2025-11-12T10:03:22.340695Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 37.15772187s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 34.955393065s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 30.755542238s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 22.595489334s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "].\n",
      "{\"timestamp\": \"2025-11-12T10:04:06.889429Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:04:06.893425Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:04:06.897427Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:04:06.905426Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_153406_3e72d3d6\", \"temp_dir\": \"data\\\\session_20251112_153406_3e72d3d6\", \"faiss_dir\": \"faiss_index\\\\session_20251112_153406_3e72d3d6\", \"sessionized\": true, \"timestamp\": \"2025-11-12T10:04:06.913926Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_153406_3e72d3d6\\\\22a2c76a.txt\", \"timestamp\": \"2025-11-12T10:04:06.923010Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T10:04:06.933033Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T10:04:06.938360Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:04:06.944652Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_153406_3e72d3d6\", \"timestamp\": \"2025-11-12T10:04:09.995620Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T10:04:09.999621Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T10:04:10.007635Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:04:10.012620Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:04:10.015626Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:04:10.025185Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T10:04:10.028175Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_153406_3e72d3d6\", \"timestamp\": \"2025-11-12T10:04:10.042177Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153406_3e72d3d6\", \"timestamp\": \"2025-11-12T10:04:10.047190Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T10:04:10.055175Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:04:10.058177Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:04:10.064180Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:04:10.076176Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:04:10.080178Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_153406_3e72d3d6\", \"timestamp\": \"2025-11-12T10:04:10.205264Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_153406_3e72d3d6\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_153406_3e72d3d6\", \"timestamp\": \"2025-11-12T10:04:10.209265Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153406_3e72d3d6\", \"user_input\": \"What challenges or cautions were associated with agentic AI adoption?\", \"answer_preview\": \"Industry analysts warned of \\\"agent washing\\\" and predicted many agentic projects would fail to deliver ROI without clear business value and engineering\", \"timestamp\": \"2025-11-12T10:04:15.142837Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 40.62359472s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 40\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 38.374072432s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 38\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 34.175891624s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 25.992801778s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "].\n",
      "{\"timestamp\": \"2025-11-12T10:05:02.255109Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:02.260106Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:05:02.264105Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:02.272096Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_153502_9e6c014b\", \"temp_dir\": \"data\\\\session_20251112_153502_9e6c014b\", \"faiss_dir\": \"faiss_index\\\\session_20251112_153502_9e6c014b\", \"sessionized\": true, \"timestamp\": \"2025-11-12T10:05:02.280640Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_153502_9e6c014b\\\\ae6b0b69.txt\", \"timestamp\": \"2025-11-12T10:05:02.289640Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T10:05:02.295650Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T10:05:02.299648Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:05:02.304646Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_153502_9e6c014b\", \"timestamp\": \"2025-11-12T10:05:05.927188Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T10:05:05.931191Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:05.937184Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:05.941189Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:05:05.944188Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:05.952681Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T10:05:05.955684Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_153502_9e6c014b\", \"timestamp\": \"2025-11-12T10:05:05.968677Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153502_9e6c014b\", \"timestamp\": \"2025-11-12T10:05:05.970684Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:05.979668Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:05.981671Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:05:05.982671Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:05.989676Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:05:05.993673Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_153502_9e6c014b\", \"timestamp\": \"2025-11-12T10:05:06.062704Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_153502_9e6c014b\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_153502_9e6c014b\", \"timestamp\": \"2025-11-12T10:05:06.065703Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153502_9e6c014b\", \"user_input\": \"What is meant by 'agentic AI,' and how did it evolve in 2025?\", \"answer_preview\": \"Agentic AI refers to systems that autonomously plan and execute multi-step tasks. In 2025, it emerged as a prominent strategic trend, with vendors rol\", \"timestamp\": \"2025-11-12T10:05:11.557580Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:27.699363Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:27.703279Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:05:27.706727Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:27.715719Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"session_id\": \"session_20251112_153527_2f6f46b8\", \"temp_dir\": \"data\\\\session_20251112_153527_2f6f46b8\", \"faiss_dir\": \"faiss_index\\\\session_20251112_153527_2f6f46b8\", \"sessionized\": true, \"timestamp\": \"2025-11-12T10:05:27.726400Z\", \"level\": \"info\", \"event\": \"ChatIngestor initialized\"}\n",
      "{\"uploaded\": \"rag_data.txt\", \"saved_as\": \"data\\\\session_20251112_153527_2f6f46b8\\\\d32e1a13.txt\", \"timestamp\": \"2025-11-12T10:05:27.737526Z\", \"level\": \"info\", \"event\": \"File saved for ingestion\"}\n",
      "{\"count\": 1, \"timestamp\": \"2025-11-12T10:05:27.744525Z\", \"level\": \"info\", \"event\": \"Documents loaded\"}\n",
      "{\"chunks\": 7, \"chunk_size\": 1000, \"overlap\": 200, \"timestamp\": \"2025-11-12T10:05:27.748526Z\", \"level\": \"info\", \"event\": \"Documents split\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:05:27.754548Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"added\": 1, \"index\": \"faiss_index\\\\session_20251112_153527_2f6f46b8\", \"timestamp\": \"2025-11-12T10:05:29.380019Z\", \"level\": \"info\", \"event\": \"FAISS index updated\"}\n",
      "{\"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"timestamp\": \"2025-11-12T10:05:29.384018Z\", \"level\": \"info\", \"event\": \"Using MMR search\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:29.391026Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:29.394015Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:05:29.398019Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:29.411016Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"provider\": \"google\", \"model\": \"gemini-2.5-flash\", \"timestamp\": \"2025-11-12T10:05:29.414020Z\", \"level\": \"info\", \"event\": \"Loading LLM\"}\n",
      "{\"session_id\": \"session_20251112_153527_2f6f46b8\", \"timestamp\": \"2025-11-12T10:05:29.428018Z\", \"level\": \"info\", \"event\": \"LLM loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153527_2f6f46b8\", \"timestamp\": \"2025-11-12T10:05:29.432026Z\", \"level\": \"info\", \"event\": \"ConversationalRAG initialized\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:29.443035Z\", \"level\": \"info\", \"event\": \"running in local mode:.env loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:29.446429Z\", \"level\": \"info\", \"event\": \"loaded GOOGLE_API_KEY from individual env var\"}\n",
      "{\"keys\": {\"GOOGLE_API_KEY\": \"AIzaSy...\"}, \"timestamp\": \"2025-11-12T10:05:29.449410Z\", \"level\": \"info\", \"event\": \"API keys loaded\"}\n",
      "{\"timestamp\": \"2025-11-12T10:05:29.458764Z\", \"level\": \"info\", \"event\": \"YAML CONFIG LOADED\"}\n",
      "{\"model\": \"models/gemini-embedding-001\", \"timestamp\": \"2025-11-12T10:05:29.462271Z\", \"level\": \"info\", \"event\": \"Loading embedding model\"}\n",
      "{\"session_id\": \"session_20251112_153527_2f6f46b8\", \"timestamp\": \"2025-11-12T10:05:29.544129Z\", \"level\": \"info\", \"event\": \"LCEL graph built successfully\"}\n",
      "{\"index_path\": \"faiss_index/session_20251112_153527_2f6f46b8\", \"index_name\": \"index\", \"search_type\": \"mmr\", \"k\": 5, \"fetch_k\": 20, \"lambda_mult\": 0.5, \"session_id\": \"session_20251112_153527_2f6f46b8\", \"timestamp\": \"2025-11-12T10:05:29.548169Z\", \"level\": \"info\", \"event\": \"FAISS retriever loaded successfully\"}\n",
      "{\"session_id\": \"session_20251112_153527_2f6f46b8\", \"user_input\": \"What practical advice does the summary offer to engineers and researchers?\", \"answer_preview\": \"Engineers and researchers should choose the right model family for their task, with top-tier closed models often favored for reasoning/math/coding, wh\", \"timestamp\": \"2025-11-12T10:05:36.506220Z\", \"level\": \"info\", \"event\": \"Chain invoked successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ExperimentResults ai_rag-cf0f6eb4>\n"
     ]
    }
   ],
   "source": [
    "from langsmith import evaluate, Client\n",
    "from langsmith.schemas import Run, Example\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Custom correctness evaluator: LLM-as-judge\n",
    "def correctness_evaluator(run: Run, example: Example) -> dict:\n",
    "    actual_output = run.outputs.get(\"answer\", \"\")\n",
    "    expected_output = example.outputs.get(\"answer\", \"\")\n",
    "    input_question = example.inputs.get(\"question\", \"\")\n",
    "\n",
    "    eval_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are an evaluator whose job is to judge correctness.\n",
    "\n",
    "Correctness means how well the actual model output matches the reference output in terms of factual accuracy, coverage, and meaning.\n",
    "\n",
    "- If the actual output matches the reference output semantically (even if wording differs), it should be marked correct.\n",
    "- If the output misses key facts, introduces contradictions, or is factually incorrect, it should be marked incorrect.\n",
    "\n",
    "Do not penalize for stylistic or formatting differences unless they change meaning.\"\"\"),\n",
    "\n",
    "        (\"human\", f\"\"\"<example>\n",
    "<input>\n",
    "{input_question}\n",
    "</input>\n",
    "\n",
    "<output>\n",
    "Expected Output: {expected_output}\n",
    "\n",
    "Actual Output: {actual_output}\n",
    "</output>\n",
    "</example>\n",
    "\n",
    "Please grade the following agent run given the input, expected output, and actual output.\n",
    "Focus only on correctness (semantic and factual alignment).\n",
    "\n",
    "Respond with:\n",
    "1. A brief reasoning (1-2 sentences)\n",
    "2. A final verdict: either \"CORRECT\" or \"INCORRECT\"\n",
    "\n",
    "Format your response as:\n",
    "Reasoning: [your reasoning]\n",
    "Verdict: [CORRECT or INCORRECT]\"\"\")\n",
    "    ])\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0)\n",
    "    chain = eval_prompt | llm\n",
    "\n",
    "    try:\n",
    "        response = chain.invoke({\n",
    "            \"input\": input_question,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"actual_output\": actual_output\n",
    "        })\n",
    "\n",
    "        response_text = response.content\n",
    "        reasoning = None\n",
    "        verdict = None\n",
    "        for line in response_text.split(\"\\n\"):\n",
    "            if line.startswith(\"Reasoning:\"):\n",
    "                reasoning = line.replace(\"Reasoning:\", \"\").strip()\n",
    "            elif line.startswith(\"Verdict:\"):\n",
    "                verdict = line.replace(\"Verdict:\", \"\").strip()\n",
    "\n",
    "        score = 1 if verdict and verdict.upper() == \"CORRECT\" else 0\n",
    "\n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": score,\n",
    "            \"reasoning\": reasoning or \"\",\n",
    "            \"comment\": f\"Verdict: {verdict}\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"key\": \"correctness\",\n",
    "            \"score\": 0,\n",
    "            \"reasoning\": f\"Error during evaluation: {str(e)}\"\n",
    "        }\n",
    "\n",
    "\n",
    "# Evaluation run using the custom evaluator\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"aidommydataset\" # your dataset name\n",
    "\n",
    "experiment_results = evaluate(\n",
    "    answer_ai_report_question,     # your RAG function (callable)\n",
    "    data=dataset_name,\n",
    "    evaluators=[correctness_evaluator],  # list of evaluator functions\n",
    "    experiment_prefix=\"ai_rag\",\n",
    "    description=\"Evaluating RAG system with custom correctness evaluator (LLM-as-a-Judge)\",\n",
    "    metadata={\n",
    "        \"variant\": \"RAG with FAISS and AI Engineering Report\",\n",
    "        \"evaluator\": \"custom_correctness_llm_judge\",\n",
    "        \"model\": \"gemini-2.5-pro\",\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 200,\n",
    "        \"k\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(experiment_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb01d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mulitdocchatapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
